{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e0018fb-f29e-4c6a-a713-c9f82ff0a440",
   "metadata": {},
   "source": [
    "# Libraries and s3 connexion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67017e6c-b574-4428-bbc9-fde13c8e606d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41440b7f-1caa-40f2-b113-43e7e671de7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import s3fs\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec08b6d9-d78d-4042-9073-aa973148633f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = s3fs.S3FileSystem(\n",
    "    client_kwargs={\"endpoint_url\": f'https://{os.environ[\"AWS_S3_ENDPOINT\"]}'},\n",
    "    key=os.environ[\"AWS_ACCESS_KEY_ID\"],\n",
    "    secret=os.environ[\"AWS_SECRET_ACCESS_KEY\"],\n",
    "    token=os.environ[\"AWS_SESSION_TOKEN\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4dd2d8-2e6b-4db0-b396-f8b870a0e68a",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fee0f6df-d5c0-43de-b0cc-1855bd7be8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargement de projet-slums-detection/challenge_mexique/.keep vers data/.keep\n",
      "Téléchargement de projet-slums-detection/challenge_mexique/SampleSubmission.csv vers data/SampleSubmission.csv\n",
      "Téléchargement de projet-slums-detection/challenge_mexique/id_map.csv vers data/id_map.csv\n",
      "Téléchargement de projet-slums-detection/challenge_mexique/test_data.h5 vers data/test_data.h5\n",
      "Téléchargement de projet-slums-detection/challenge_mexique/train_data.h5 vers data/train_data.h5\n"
     ]
    }
   ],
   "source": [
    "def download_s3_folder(fs, bucket_name, s3_folder, local_dir):\n",
    "    \"\"\"\n",
    "    Télécharge tous les fichiers d'un dossier S3 dans un répertoire local.\n",
    "    \n",
    "    :param bucket_name: Nom du bucket S3.\n",
    "    :param s3_folder: Chemin du dossier sur S3 à télécharger.\n",
    "    :param local_dir: Chemin local où télécharger les fichiers.\n",
    "    \"\"\"\n",
    "    files = fs.ls(f\"{bucket_name}/{s3_folder}\")\n",
    "\n",
    "    for file in files:\n",
    "        file_path = file.replace(bucket_name+s3_folder, \"\")\n",
    "        local_file_path = os.path.join(local_dir, file_path)\n",
    "\n",
    "        local_file_dir = os.path.dirname(local_file_path)\n",
    "        if not os.path.exists(local_file_dir):\n",
    "            os.makedirs(local_file_dir)\n",
    "\n",
    "        print(f\"Téléchargement de {file} vers {local_file_path}\")\n",
    "        fs.get(file, local_file_path)\n",
    "\n",
    "# Téléchargement des données\n",
    "bucket_name = 'projet-slums-detection/'\n",
    "s3_folder = 'challenge_mexique/'\n",
    "local_dir = 'data/'\n",
    "\n",
    "download_s3_folder(fs, bucket_name, s3_folder, local_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309e1a72-b333-4d65-ad16-364d7943fb32",
   "metadata": {},
   "source": [
    "## Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24c54df6-8a25-4920-9cce-0a85394c65d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_794805/4146447924.py:7: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n",
      "  X = np.array(hdf['images'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X (images): (1100000, 16, 16, 6)\n",
      "Shape of y (labels): (1100000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_794805/4146447924.py:10: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n",
      "  y = np.array(hdf['labels'])\n"
     ]
    }
   ],
   "source": [
    "# Path to your HDF5 file\n",
    "hdf5_file = \"../data/train_data.h5\"\n",
    "\n",
    "# Open the HDF5 file\n",
    "with h5py.File(hdf5_file, 'r') as hdf:\n",
    "    # Extract the images (X)\n",
    "    X = np.array(hdf['images'])\n",
    "    \n",
    "    # Extract the labels (y)\n",
    "    y = np.array(hdf['labels'])\n",
    "\n",
    "# Check the shapes to ensure they are correct\n",
    "print(\"Shape of X (images):\", X.shape)\n",
    "print(\"Shape of y (labels):\", y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776ce6fa-05c0-4374-9460-63044111f44b",
   "metadata": {},
   "source": [
    "### Visualize first image (uint16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5581d334-ae4d-4eec-9256-94a8cafbb3fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1100000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "90198231-a07c-4510-8df7-7137f05eeda6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot l'image 50\n",
    "image_array = X[300000]\n",
    "\n",
    "rgb_image = np.stack([image_array[:, :, 3], image_array[:, :, 4], image_array[:, :, 5]], axis=-1)\n",
    "\n",
    "# Normalize the image for display (optional if values exceed standard 8-bit range)\n",
    "rgb_image_normalized = rgb_image / np.max(rgb_image)\n",
    "\n",
    "# Plot the RGB image\n",
    "plt.imshow(rgb_image_normalized)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daddeb19-f826-4a14-9b77-21df84373eca",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73622f54-fa40-436c-946f-342ebeb29789",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_file_test = \"data/test_data.h5\"\n",
    "# Open the HDF5 file\n",
    "with h5py.File(hdf5_file_test, 'r') as hdf:\n",
    "    # Extract the images (X)\n",
    "    X_test = np.array(hdf['images'])\n",
    "\n",
    "# Check the shapes to ensure they are correct\n",
    "print(\"Shape of X_test (images):\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2ca083-2281-4927-9d7a-12dd48431c26",
   "metadata": {},
   "source": [
    "### Create y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ceac53-7bfc-425d-b4a9-55bf6e804f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = pd.read_csv(\"data/id_map.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cb409a-dc9f-4cc1-a550-5f54585d221c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv(\"data/SampleSubmission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b0b8f0-e07c-43a6-9558-bdf43b065410",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.merge(sample, mapping, on=\"id\")\n",
    "y_test = y_test.sort_values(by=\"ID\", ascending=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "y_test = np.array(y_test['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ee615f-a496-4c17-b188-5f1d38ee96a8",
   "metadata": {},
   "source": [
    "### Balance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d46491-3761-4676-9fa8-4a8efb0f2bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_data(X, y, prop_of_zeros=0.5):\n",
    "    # Step 1: Count the number of 1's in y\n",
    "    num_ones = np.sum(y == 1)\n",
    "    \n",
    "    # Step 2: Get indices of 0's and 1's in y\n",
    "    ones_indices = np.where(y == 1)[0]\n",
    "    zeros_indices = np.where(y == 0)[0]\n",
    "    \n",
    "    # Step 3: Randomly sample the same number of 0's as there are 1's\n",
    "    balanced_zero_indices = np.random.choice(zeros_indices, int(int(num_ones)*prop_of_zeros/(1-prop_of_zeros)), replace=False)\n",
    "    \n",
    "    # Step 4: Combine indices of 0's and 1's\n",
    "    balanced_indices = np.concatenate([ones_indices, balanced_zero_indices])\n",
    "    \n",
    "    # Step 5: Create balanced X and y\n",
    "    X_balanced = X[balanced_indices]\n",
    "    y_balanced = y[balanced_indices]\n",
    "    \n",
    "    # Display the number of 0's and 1's in the balanced y\n",
    "    print(f\"Number of 1's in balanced y: {np.sum(y_balanced == 1)}\")\n",
    "    print(f\"Number of 0's in balanced y: {np.sum(y_balanced == 0)}\")\n",
    "\n",
    "    # Shuffle both X_balanced and y_balanced together\n",
    "    X_balanced, y_balanced = shuffle(X_balanced, y_balanced, random_state=1)\n",
    "\n",
    "    return X_balanced, y_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a18a55d6-48b5-41a1-bffb-39c89fe76af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 1's in balanced y: 100000\n",
      "Number of 0's in balanced y: 100000\n"
     ]
    }
   ],
   "source": [
    "X_balanced, y_balanced = balance_data(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ac6bc6-eaa0-49a3-b777-291605aed83f",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f1a0522b-c603-41f2-877a-ea193772b97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Supposons que vous ayez X (features) et y (labels)\n",
    "# X : np.array de vos matrices d'entrée (par exemple, shape (n_samples, 16, 16, 6))\n",
    "# y : np.array de vos labels (0 ou 1), shape (n_samples,)\n",
    "\n",
    "def split_data(X, y, train_size=0.6, val_size=0.2, test_size=0.2):\n",
    "    # Vérifier que les tailles des splits sont cohérentes\n",
    "    assert train_size + val_size + test_size == 1, \"Les tailles des splits doivent être égales à 1\"\n",
    "    \n",
    "    # Séparer les données par classe\n",
    "    X_class0 = X[y == 0]\n",
    "    X_class1 = X[y == 1]\n",
    "    \n",
    "    y_class0 = y[y == 0]\n",
    "    y_class1 = y[y == 1]\n",
    "    \n",
    "    # Diviser chaque classe en train, validation, test\n",
    "    # Classe 0\n",
    "    X_train_0, X_temp_0, y_train_0, y_temp_0 = train_test_split(X_class0, y_class0, train_size=train_size, stratify=y_class0)\n",
    "    X_val_0, X_test_0, y_val_0, y_test_0 = train_test_split(X_temp_0, y_temp_0, test_size=test_size/(test_size + val_size), stratify=y_temp_0)\n",
    "    \n",
    "    # Classe 1\n",
    "    X_train_1, X_temp_1, y_train_1, y_temp_1 = train_test_split(X_class1, y_class1, train_size=train_size, stratify=y_class1)\n",
    "    X_val_1, X_test_1, y_val_1, y_test_1 = train_test_split(X_temp_1, y_temp_1, test_size=test_size/(test_size + val_size), stratify=y_temp_1)\n",
    "    \n",
    "    # Combiner les données de classe 0 et classe 1\n",
    "    X_train = np.concatenate([X_train_0, X_train_1], axis=0)\n",
    "    y_train = np.concatenate([y_train_0, y_train_1], axis=0)\n",
    "    \n",
    "    X_val = np.concatenate([X_val_0, X_val_1], axis=0)\n",
    "    y_val = np.concatenate([y_val_0, y_val_1], axis=0)\n",
    "    \n",
    "    X_test = np.concatenate([X_test_0, X_test_1], axis=0)\n",
    "    y_test = np.concatenate([y_test_0, y_test_1], axis=0)\n",
    "    \n",
    "    # Shuffle les ensembles pour mélanger les classes\n",
    "    train_indices = np.random.permutation(X_train.shape[0])\n",
    "    val_indices = np.random.permutation(X_val.shape[0])\n",
    "    test_indices = np.random.permutation(X_test.shape[0])\n",
    "    \n",
    "    X_train, y_train = X_train[train_indices], y_train[train_indices]\n",
    "    X_val, y_val = X_val[val_indices], y_val[val_indices]\n",
    "    X_test, y_test = X_test[test_indices], y_test[test_indices]\n",
    "    \n",
    "    return (X_train, y_train), (X_val, y_val), (X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2bf02c7a-f4f7-476a-8c41-048c89d1f6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille des données d'entraînement : (120000, 16, 16, 6) (120000,)\n",
      "Taille des données de validation : (40000, 16, 16, 6) (40000,)\n",
      "Taille des données de test : (40000, 16, 16, 6) (40000,)\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_val, y_val), (X_test, y_test) = split_data(X_balanced, y_balanced)\n",
    "\n",
    "# Vérification de la taille des jeux de données\n",
    "print(\"Taille des données d'entraînement :\", X_train.shape, y_train.shape)\n",
    "print(\"Taille des données de validation :\", X_val.shape, y_val.shape)\n",
    "print(\"Taille des données de test :\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3979063c-4f54-4274-871b-0775c04b5f0c",
   "metadata": {},
   "source": [
    "## Entrainements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c347e6-a71c-48c3-a6da-b5a41d591c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tester la nouvelle architecture avec une entrée 16x16x6\n",
    "x = torch.randn(1, 6, 16, 16)  # Batch de 1, 6 canaux, 16x16\n",
    "output = model(x)\n",
    "\n",
    "print(output.shape)  # Sortie du réseau"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
