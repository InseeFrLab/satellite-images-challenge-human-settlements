{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e0018fb-f29e-4c6a-a713-c9f82ff0a440",
   "metadata": {},
   "source": [
    "# Libraries and s3 connexion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67017e6c-b574-4428-bbc9-fde13c8e606d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install h5py rasterio torch torchvision pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41440b7f-1caa-40f2-b113-43e7e671de7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import s3fs\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec08b6d9-d78d-4042-9073-aa973148633f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = s3fs.S3FileSystem(\n",
    "    client_kwargs={\"endpoint_url\": f'https://{os.environ[\"AWS_S3_ENDPOINT\"]}'},\n",
    "    key=os.environ[\"AWS_ACCESS_KEY_ID\"],\n",
    "    secret=os.environ[\"AWS_SECRET_ACCESS_KEY\"],\n",
    "    token=os.environ[\"AWS_SESSION_TOKEN\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4dd2d8-2e6b-4db0-b396-f8b870a0e68a",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fee0f6df-d5c0-43de-b0cc-1855bd7be8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargement de projet-slums-detection/challenge_mexique/.keep vers data/.keep\n",
      "Téléchargement de projet-slums-detection/challenge_mexique/SampleSubmission.csv vers data/SampleSubmission.csv\n",
      "Téléchargement de projet-slums-detection/challenge_mexique/id_map.csv vers data/id_map.csv\n",
      "Téléchargement de projet-slums-detection/challenge_mexique/test_data.h5 vers data/test_data.h5\n",
      "Téléchargement de projet-slums-detection/challenge_mexique/train_data.h5 vers data/train_data.h5\n"
     ]
    }
   ],
   "source": [
    "def download_s3_folder(fs, bucket_name, s3_folder, local_dir):\n",
    "    \"\"\"\n",
    "    Télécharge tous les fichiers d'un dossier S3 dans un répertoire local.\n",
    "    \n",
    "    :param bucket_name: Nom du bucket S3.\n",
    "    :param s3_folder: Chemin du dossier sur S3 à télécharger.\n",
    "    :param local_dir: Chemin local où télécharger les fichiers.\n",
    "    \"\"\"\n",
    "    files = fs.ls(f\"{bucket_name}/{s3_folder}\")\n",
    "\n",
    "    for file in files:\n",
    "        file_path = file.replace(bucket_name+s3_folder, \"\")\n",
    "        local_file_path = os.path.join(local_dir, file_path)\n",
    "\n",
    "        local_file_dir = os.path.dirname(local_file_path)\n",
    "        if not os.path.exists(local_file_dir):\n",
    "            os.makedirs(local_file_dir)\n",
    "\n",
    "        print(f\"Téléchargement de {file} vers {local_file_path}\")\n",
    "        fs.get(file, local_file_path)\n",
    "\n",
    "# Téléchargement des données\n",
    "bucket_name = 'projet-slums-detection/'\n",
    "s3_folder = 'challenge_mexique/'\n",
    "local_dir = 'data/'\n",
    "\n",
    "download_s3_folder(fs, bucket_name, s3_folder, local_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309e1a72-b333-4d65-ad16-364d7943fb32",
   "metadata": {},
   "source": [
    "## Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24c54df6-8a25-4920-9cce-0a85394c65d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1982/308163644.py:7: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n",
      "  X = np.array(hdf['images'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X (images): (1100000, 16, 16, 6)\n",
      "Shape of y (labels): (1100000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1982/308163644.py:10: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n",
      "  y = np.array(hdf['labels'])\n"
     ]
    }
   ],
   "source": [
    "# Path to your HDF5 file\n",
    "hdf5_file = \"data/train_data.h5\"\n",
    "\n",
    "# Open the HDF5 file\n",
    "with h5py.File(hdf5_file, 'r') as hdf:\n",
    "    # Extract the images (X)\n",
    "    X = np.array(hdf['images'])\n",
    "    \n",
    "    # Extract the labels (y)\n",
    "    y = np.array(hdf['labels'])\n",
    "\n",
    "# Check the shapes to ensure they are correct\n",
    "print(\"Shape of X (images):\", X.shape)\n",
    "print(\"Shape of y (labels):\", y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776ce6fa-05c0-4374-9460-63044111f44b",
   "metadata": {},
   "source": [
    "### Visualize first image (uint16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5581d334-ae4d-4eec-9256-94a8cafbb3fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1100000"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90198231-a07c-4510-8df7-7137f05eeda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot l'image 50\n",
    "image_array = X[50]\n",
    "\n",
    "rgb_image = np.stack([image_array[:, :, 3], image_array[:, :, 4], image_array[:, :, 5]], axis=-1)\n",
    "\n",
    "# Normalize the image for display (optional if values exceed standard 8-bit range)\n",
    "rgb_image_normalized = rgb_image / np.max(rgb_image)\n",
    "\n",
    "# Plot the RGB image\n",
    "plt.imshow(rgb_image_normalized)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daddeb19-f826-4a14-9b77-21df84373eca",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73622f54-fa40-436c-946f-342ebeb29789",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_file_test = \"data/test_data.h5\"\n",
    "# Open the HDF5 file\n",
    "with h5py.File(hdf5_file_test, 'r') as hdf:\n",
    "    # Extract the images (X)\n",
    "    X_test = np.array(hdf['images'])\n",
    "\n",
    "# Check the shapes to ensure they are correct\n",
    "print(\"Shape of X_test (images):\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2ca083-2281-4927-9d7a-12dd48431c26",
   "metadata": {},
   "source": [
    "### Create y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ceac53-7bfc-425d-b4a9-55bf6e804f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = pd.read_csv(\"data/id_map.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cb409a-dc9f-4cc1-a550-5f54585d221c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv(\"data/SampleSubmission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b0b8f0-e07c-43a6-9558-bdf43b065410",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.merge(sample, mapping, on=\"id\")\n",
    "y_test = y_test.sort_values(by=\"ID\", ascending=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "y_test = np.array(y_test['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ee615f-a496-4c17-b188-5f1d38ee96a8",
   "metadata": {},
   "source": [
    "### Balance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf89543b-2b49-4fc1-812b-18166da0553a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_data(X, y, prop_of_zeros=0.5):\n",
    "    # Step 1: Count the number of 1's in y\n",
    "    num_ones = np.sum(y == 1)\n",
    "    \n",
    "    # Step 2: Get indices of 0's and 1's in y\n",
    "    ones_indices = np.where(y == 1)[0]\n",
    "    zeros_indices = np.where(y == 0)[0]\n",
    "    \n",
    "    # Step 3: Randomly sample the same number of 0's as there are 1's\n",
    "    balanced_zero_indices = np.random.choice(zeros_indices, int(int(num_ones)*prop_of_zeros), replace=False)\n",
    "    \n",
    "    # Step 4: Combine indices of 0's and 1's\n",
    "    balanced_indices = np.concatenate([ones_indices, balanced_zero_indices])\n",
    "    \n",
    "    # Step 5: Create balanced X and y\n",
    "    X_balanced = X[balanced_indices]\n",
    "    y_balanced = y[balanced_indices]\n",
    "    \n",
    "    # Display the number of 0's and 1's in the balanced y\n",
    "    print(f\"Number of 1's in balanced y: {np.sum(y_balanced == 1)}\")\n",
    "    print(f\"Number of 0's in balanced y: {np.sum(y_balanced == 0)}\")\n",
    "\n",
    "    # Shuffle both X_balanced and y_balanced together\n",
    "    X_train, y_train = shuffle(X_balanced, y_balanced, random_state=1)\n",
    "\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a18a55d6-48b5-41a1-bffb-39c89fe76af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 1's in balanced y: 100000\n",
      "Number of 0's in balanced y: 50000\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = balance_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c586387a-076e-43d5-98a4-20ccdee287a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150000, 16, 16, 6)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3979063c-4f54-4274-871b-0775c04b5f0c",
   "metadata": {},
   "source": [
    "## Entrainements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c347e6-a71c-48c3-a6da-b5a41d591c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tester la nouvelle architecture avec une entrée 16x16x6\n",
    "x = torch.randn(1, 6, 16, 16)  # Batch de 1, 6 canaux, 16x16\n",
    "output = model(x)\n",
    "\n",
    "print(output.shape)  # Sortie du réseau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4b5cf1-25ee-4cc3-9f51-fd311c8acb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import csv\n",
    "import shutil\n",
    "from osgeo import gdal\n",
    "\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import yaml\n",
    "from pytorch_lightning.callbacks import (\n",
    "    EarlyStopping,\n",
    "    LearningRateMonitor,\n",
    "    ModelCheckpoint,\n",
    ")\n",
    "from rasterio.errors import RasterioIOError\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from tqdm import tqdm\n",
    "from yaml.loader import SafeLoader\n",
    "\n",
    "from classes.data.labeled_satellite_image import (  # noqa: E501\n",
    "    SegmentationLabeledSatelliteImage,\n",
    ")\n",
    "from classes.data.satellite_image import SatelliteImage\n",
    "\n",
    "from classes.optim.optimizer import generate_optimization_elements\n",
    "from dico_config import (\n",
    "    labeler_dict,\n",
    "    dataset_dict,\n",
    "    loss_dict,\n",
    "    module_dict,\n",
    "    task_to_evaluation,\n",
    "    task_to_lightningmodule,\n",
    ")\n",
    "from train_pipeline_utils.download_data import (\n",
    "    load_2satellites_data,\n",
    "    load_donnees_test,\n",
    "    load_satellite_data,\n",
    "    load_s2_looking\n",
    ")\n",
    "from train_pipeline_utils.handle_dataset import (\n",
    "    generate_transform_pleiades,\n",
    "    generate_transform_sentinel,\n",
    "    select_indices_to_balance,\n",
    "    select_indices_to_split_dataset,\n",
    ")\n",
    "from train_pipeline_utils.prepare_data import (\n",
    "    check_labelled_images,\n",
    "    filter_images,\n",
    "    label_images,\n",
    "    save_images_and_masks,\n",
    "    extract_proportional_subset,\n",
    "    filter_images_by_path,\n",
    "    prepare_data_per_doss,\n",
    ")\n",
    "\n",
    "from utils.utils import remove_dot_file, split_array, update_storage_access, list_sorted_filenames\n",
    "\n",
    "\n",
    "def instantiate_dataset(config, list_images, list_labels, list_images_2 = None, test=False):\n",
    "    \"\"\"\n",
    "    Instantiates the appropriate dataset object\n",
    "    based on the configuration settings.\n",
    "\n",
    "    Args:\n",
    "        config: A dictionary representing the configuration settings.\n",
    "        list_path_images: A list of strings representing\n",
    "        the paths to the preprocessed tile image files.\n",
    "        list_path_labels: A list of strings representing\n",
    "        the paths to the corresponding preprocessed mask image files.\n",
    "\n",
    "    Returns:\n",
    "        A dataset object of the specified type.\n",
    "    \"\"\"\n",
    "    full_data = ResNet18_Dataset(X, y)\n",
    "    return full_dataset\n",
    "\n",
    "\n",
    "def instantiate_dataloader_s2(config, list_output_dir):\n",
    "    \"\"\"\n",
    "    Instantiates and returns the data loaders for\n",
    "    training, validation, and testing datasets.\n",
    "\n",
    "    Args:\n",
    "    - config (dict): A dictionary containing the configuration parameters\n",
    "    for data loading and processing.\n",
    "    - list_output_dir (list): A list of strings containing the paths to\n",
    "    the directories that contain the training data.\n",
    "\n",
    "    Returns:\n",
    "    - train_dataloader (torch.utils.data.DataLoader):\n",
    "    The data loader for the training dataset.\n",
    "    - valid_dataloader (torch.utils.data.DataLoader):\n",
    "    The data loader for the validation dataset.\n",
    "    - test_dataloader (torch.utils.data.DataLoader):\n",
    "    The data loader for the testing dataset.\n",
    "\n",
    "    The function first generates the paths for the image and label data\n",
    "    based on the data source (Sentinel, PLEIADES) vs pre-annotated datasets.\n",
    "    It then instantiates the required dataset class\n",
    "    (using the `intantiate_dataset` function) and splits the full dataset\n",
    "    into training and validation datasets based on the validation proportion\n",
    "    specified in the configuration parameters.\n",
    "\n",
    "    Next, the appropriate transformations are applied to the training\n",
    "    and validation datasets using the `generate_transform` function.\n",
    "\n",
    "    Finally, the data loaders for the training and validation datasets\n",
    "    are created using the `DataLoader` class from the PyTorch library,\n",
    "    and the data loader for the testing dataset is set to `None`.\n",
    "    \"\"\"\n",
    "    # génération des paths en fonction du type de Données\n",
    "    # (Sentinel, PLEIADES) VS Dataset préannotés\n",
    "\n",
    "    print(\"Entre dans la fonction instantiate_dataloader\")\n",
    "\n",
    "    output_dir_train, output_dir_valid, output_dir_test = list_output_dir\n",
    "\n",
    "    train_list_images1 = list_sorted_filenames(output_dir_train + \"Image1/\")\n",
    "    train_list_images2 = list_sorted_filenames(output_dir_train + \"Image2/\")\n",
    "    train_list_labels = list_sorted_filenames(output_dir_train + \"label/\")\n",
    "\n",
    "    val_list_images1 = list_sorted_filenames(output_dir_valid + \"Image1/\")\n",
    "    val_list_images2 = list_sorted_filenames(output_dir_valid + \"Image2/\")\n",
    "    val_list_labels = list_sorted_filenames(output_dir_valid + \"label/\")\n",
    "\n",
    "    test_list_images1 = list_sorted_filenames(output_dir_test + \"Image1/\")\n",
    "    test_list_images2 = list_sorted_filenames(output_dir_test + \"Image2/\")\n",
    "    test_list_labels = list_sorted_filenames(output_dir_test + \"label/\")\n",
    "\n",
    "    # Retrieving the desired Dataset class\n",
    "    train_dataset = instantiate_dataset(\n",
    "        config, train_list_images1, train_list_labels,  train_list_images2\n",
    "    )\n",
    "\n",
    "    valid_dataset = instantiate_dataset(\n",
    "        config, val_list_images1, val_list_labels, val_list_images2\n",
    "    )\n",
    "\n",
    "    test_dataset = instantiate_dataset(\n",
    "        config, test_list_images1, test_list_labels, test_list_images2\n",
    "    )\n",
    "\n",
    "    tile_size = config[\"donnees\"][\"tile size\"]\n",
    "\n",
    "    t_aug, t_preproc = generate_transform_pleiades(\n",
    "        tile_size,\n",
    "        True,\n",
    "    )\n",
    "\n",
    "    train_dataset.transforms = t_aug\n",
    "    valid_dataset.transforms = t_preproc\n",
    "    test_dataset.transforms = t_preproc\n",
    "\n",
    "    # Creation of the dataloaders\n",
    "    shuffle_bool = [True, False, False]\n",
    "    batch_size = config[\"optim\"][\"batch size\"]\n",
    "    batch_size_test = config[\"optim\"][\"batch size test\"]\n",
    "\n",
    "    train_dataloader, valid_dataloader, test_dataloader = [\n",
    "        DataLoader(\n",
    "            ds, batch_size=size, shuffle=boolean, num_workers=0, drop_last=True\n",
    "        )\n",
    "        for ds, boolean, size in zip([train_dataset, valid_dataset, test_dataset], shuffle_bool, [batch_size, batch_size, batch_size_test])\n",
    "    ]\n",
    "    return train_dataloader, valid_dataloader, test_dataloader\n",
    "\n",
    "\n",
    "def instantiate_dataloader_else(config, list_output_dir, output_test):\n",
    "    \"\"\"\n",
    "    Instantiates and returns the data loaders for\n",
    "    training, validation, and testing datasets.\n",
    "\n",
    "    Args:\n",
    "    - config (dict): A dictionary containing the configuration parameters\n",
    "    for data loading and processing.\n",
    "    - list_output_dir (list): A list of strings containing the paths to\n",
    "    the directories that contain the training data.\n",
    "\n",
    "    Returns:\n",
    "    - train_dataloader (torch.utils.data.DataLoader):\n",
    "    The data loader for the training dataset.\n",
    "    - valid_dataloader (torch.utils.data.DataLoader):\n",
    "    The data loader for the validation dataset.\n",
    "    - test_dataloader (torch.utils.data.DataLoader):\n",
    "    The data loader for the testing dataset.\n",
    "\n",
    "    The function first generates the paths for the image and label data\n",
    "    based on the data source (Sentinel, PLEIADES) vs pre-annotated datasets.\n",
    "    It then instantiates the required dataset class\n",
    "    (using the `intantiate_dataset` function) and splits the full dataset\n",
    "    into training and validation datasets based on the validation proportion\n",
    "    specified in the configuration parameters.\n",
    "\n",
    "    Next, the appropriate transformations are applied to the training\n",
    "    and validation datasets using the `generate_transform` function.\n",
    "\n",
    "    Finally, the data loaders for the training and validation datasets\n",
    "    are created using the `DataLoader` class from the PyTorch library,\n",
    "    and the data loader for the testing dataset is set to `None`.\n",
    "    \"\"\"\n",
    "    # génération des paths en fonction du type de Données\n",
    "    # (Sentinel, PLEIADES) VS Dataset préannotés\n",
    "\n",
    "    print(\"Entre dans la fonction instantiate_dataloader\")\n",
    "    config_task = config[\"donnees\"][\"task\"]\n",
    "    prop = config[\"donnees\"][\"prop\"]\n",
    "    if config[\"donnees\"][\"source train\"] in [\n",
    "        \"PLEIADES\",\n",
    "        \"SENTINEL2\",\n",
    "        \"SENTINEL1-2\",\n",
    "        \"SENTINEL2-RVB\",\n",
    "        \"SENTINEL1-2-RVB\"\n",
    "    ]:\n",
    "        list_labels = []\n",
    "        list_images = []\n",
    "        full_balancing_dict = {}\n",
    "        for directory in list_output_dir:\n",
    "            # directory = list_output_dir[0]\n",
    "            labels = os.listdir(directory + \"/labels\")\n",
    "            images = os.listdir(directory + \"/images\")\n",
    "            labels = remove_dot_file(labels)\n",
    "\n",
    "            if config_task != \"classification\":\n",
    "                with open(directory + \"/balancing_dict.json\") as json_file:\n",
    "                    balancing_dict = json.load(json_file)\n",
    "\n",
    "                list_labels = np.concatenate(\n",
    "                    (\n",
    "                        list_labels,\n",
    "                        np.sort([directory + \"/labels/\" + name for name in labels]),\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                for k, v in balancing_dict.items():\n",
    "                    full_balancing_dict[k] = v\n",
    "\n",
    "            if config_task == \"classification\":\n",
    "                list_labels_dir = []\n",
    "                csv_labeler = directory + \"/labels/\" + labels[0]\n",
    "\n",
    "                # Balancing data\n",
    "                extract_proportional_subset(\n",
    "                    input_file=csv_labeler,\n",
    "                    prop=prop,\n",
    "                )\n",
    "\n",
    "                filter_images_by_path(\n",
    "                    csv_file=csv_labeler,\n",
    "                    image_folder=directory + \"/images\",\n",
    "                )\n",
    "\n",
    "                # Load the initial CSV file\n",
    "                df = pd.read_csv(csv_labeler)\n",
    "\n",
    "                list_labels_dir = df[[\"Path_image\", \"Classification\"]].values.tolist()\n",
    "\n",
    "                list_labels_dir = sorted(list_labels_dir, key=lambda x: x[0])\n",
    "                list_labels_dir = np.array(\n",
    "                    [sous_liste[1] for sous_liste in list_labels_dir]\n",
    "                )\n",
    "\n",
    "                list_labels = np.concatenate((list_labels, list_labels_dir))\n",
    "\n",
    "            list_images = np.concatenate(\n",
    "                (\n",
    "                    list_images,\n",
    "                    np.sort([directory + \"/images/\" + name for name in images]),\n",
    "                )\n",
    "            )\n",
    "\n",
    "    if config_task == \"segmentation\":\n",
    "        unbalanced_images = list_images.copy()\n",
    "        unbalanced_labels = list_labels.copy()\n",
    "        indices_to_balance = select_indices_to_balance(\n",
    "            list_images, full_balancing_dict, prop=prop\n",
    "        )\n",
    "        list_images = unbalanced_images[indices_to_balance]\n",
    "        list_labels = unbalanced_labels[indices_to_balance]\n",
    "\n",
    "    train_idx, val_idx = select_indices_to_split_dataset(\n",
    "        config_task,\n",
    "        config[\"optim\"][\"val prop\"],\n",
    "        list_labels,\n",
    "        full_balancing_dict\n",
    "    )\n",
    "\n",
    "    # Retrieving the desired Dataset class\n",
    "    train_dataset = instantiate_dataset(\n",
    "        config, list_images[train_idx], list_labels[train_idx]\n",
    "    )\n",
    "\n",
    "    valid_dataset = instantiate_dataset(\n",
    "        config, list_images[val_idx], list_labels[val_idx]\n",
    "    )\n",
    "\n",
    "    # Applying the respective transforms\n",
    "    augmentation = config[\"donnees\"][\"augmentation\"]\n",
    "    tile_size = config[\"donnees\"][\"tile size\"]\n",
    "\n",
    "    if config[\"donnees\"][\"source train\"] == \"PLEIADES\":\n",
    "        t_aug, t_preproc = generate_transform_pleiades(tile_size, augmentation)\n",
    "    else:\n",
    "        t_aug, t_preproc = generate_transform_sentinel(\n",
    "            tile_size,\n",
    "            augmentation,\n",
    "        )\n",
    "\n",
    "    train_dataset.transforms = t_aug\n",
    "    valid_dataset.transforms = t_preproc\n",
    "\n",
    "    # Creation of the dataloaders\n",
    "    batch_size = config[\"optim\"][\"batch size\"]\n",
    "\n",
    "    # Balancing batchs\n",
    "    # if config_task == \"classification\":\n",
    "    #     class_counts_train = np.bincount(train_dataset.list_labels.astype(np.int64))\n",
    "    #     class_counts_valid = np.bincount(valid_dataset.list_labels.astype(np.int64))\n",
    "\n",
    "    #     class_weights_train = class_counts_train/np.sum(class_counts_train)\n",
    "    #     train_sampler = WeightedRandomSampler(weights=class_weights_train, num_samples=len(train_dataset), replacement=True)\n",
    "\n",
    "    #     class_weights_valid = class_counts_valid/np.sum(class_counts_valid)\n",
    "    #     valid_sampler = WeightedRandomSampler(weights=class_weights_valid, num_samples=len(valid_dataset), replacement=True)\n",
    "\n",
    "    #     shuffle_bool = [False, False]\n",
    "    # else:\n",
    "    #     train_sampler, valid_sampler = None, None\n",
    "    #     shuffle_bool = [True, False]\n",
    "\n",
    "    shuffle_bool = [True, False]\n",
    "\n",
    "    train_dataloader, valid_dataloader = [\n",
    "        DataLoader(\n",
    "            ds, batch_size=batch_size, shuffle=boolean, num_workers=0, drop_last=True\n",
    "        )\n",
    "        for ds, boolean in zip([train_dataset, valid_dataset], shuffle_bool)\n",
    "    ]\n",
    "\n",
    "    # Gestion datset test\n",
    "    # output_test = \"../donnees-test/\"\n",
    "    # output_test_task = output_test + config[\"donnees\"][\"task\"]\n",
    "    # output_images_path = output_test_task + \"/images/\"\n",
    "    # output_labels_path = output_test_task + \"/masks/\"\n",
    "\n",
    "    output_labels_path = output_test + \"/labels/\"\n",
    "    list_name_label_test = os.listdir(output_labels_path)\n",
    "    list_name_label_test = remove_dot_file(list_name_label_test)\n",
    "    list_path_labels_test = np.sort([output_labels_path + name_label for name_label in list_name_label_test])\n",
    "\n",
    "    if config_task != \"change-detection\":\n",
    "        output_images_path = output_test + \"/images/\"\n",
    "        list_name_image_test = os.listdir(output_images_path)\n",
    "        list_path_images_test = np.sort([output_images_path + name_image for name_image in list_name_image_test])\n",
    "\n",
    "        if config_task == \"classification\":\n",
    "            csv_labeler = list_path_labels_test[0]\n",
    "\n",
    "            # Load the initial CSV file\n",
    "            df = pd.read_csv(csv_labeler)\n",
    "\n",
    "            list_labels_dir = df[[\"Path_image\", \"Classification\"]].values.tolist()\n",
    "\n",
    "            list_labels_dir = sorted(list_labels_dir, key=lambda x: x[0])\n",
    "            list_path_labels_test = list(np.array(\n",
    "                [sous_liste[1] for sous_liste in list_labels_dir]\n",
    "            ))\n",
    "\n",
    "        dataset_test = instantiate_dataset(\n",
    "            config, list_path_images_test, list_path_labels_test, test=True\n",
    "        )\n",
    "        dataset_test.transforms = t_preproc\n",
    "\n",
    "    else:\n",
    "\n",
    "        output_images_path_1 = output_test + \"/images_1/\"\n",
    "        list_name_image_1 = os.listdir(output_images_path_1)\n",
    "        list_path_images_1 = np.sort([output_images_path_1 + name_image for name_image in list_name_image_1])\n",
    "\n",
    "        output_images_path_2 = output_test + \"/images_2/\"\n",
    "        list_name_image_2 = os.listdir(output_images_path_2)\n",
    "        list_path_images_2 = np.sort([output_images_path_2 + name_image for name_image in list_name_image_2])\n",
    "\n",
    "        dataset_test = instantiate_dataset(\n",
    "                config, list_path_images_1, list_path_labels_test, list_images_2 = list_path_images_2, test = True\n",
    "            )\n",
    "        dataset_test.transforms = t_preproc\n",
    "\n",
    "    batch_size_test = config[\"optim\"][\"batch size test\"]\n",
    "    test_dataloader = DataLoader(\n",
    "        dataset_test,\n",
    "        batch_size=batch_size_test,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "    )\n",
    "\n",
    "    return train_dataloader, valid_dataloader, test_dataloader\n",
    "\n",
    "\n",
    "def instantiate_dataloader(config, list_output_dir, output_test):\n",
    "    \"\"\"\n",
    "    Instantiates and returns the data loaders for\n",
    "    training, validation, and testing datasets.\n",
    "\n",
    "    Args:\n",
    "    - config (dict): A dictionary containing the configuration parameters\n",
    "    for data loading and processing.\n",
    "    - list_output_dir (list): A list of strings containing the paths to\n",
    "    the directories that contain the training data.\n",
    "\n",
    "    Returns:\n",
    "    - train_dataloader (torch.utils.data.DataLoader):\n",
    "    The data loader for the training dataset.\n",
    "    - valid_dataloader (torch.utils.data.DataLoader):\n",
    "    The data loader for the validation dataset.\n",
    "    - test_dataloader (torch.utils.data.DataLoader):\n",
    "    The data loader for the testing dataset.\n",
    "\n",
    "    The function first generates the paths for the image and label data\n",
    "    based on the data source (Sentinel, PLEIADES) vs pre-annotated datasets.\n",
    "    It then instantiates the required dataset class\n",
    "    (using the `intantiate_dataset` function) and splits the full dataset\n",
    "    into training and validation datasets based on the validation proportion\n",
    "    specified in the configuration parameters.\n",
    "\n",
    "    Next, the appropriate transformations are applied to the training\n",
    "    and validation datasets using the `generate_transform` function.\n",
    "\n",
    "    Finally, the data loaders for the training and validation datasets\n",
    "    are created using the `DataLoader` class from the PyTorch library,\n",
    "    and the data loader for the testing dataset is set to `None`.\n",
    "    \"\"\"\n",
    "    # génération des paths en fonction du type de Données\n",
    "    # (Sentinel, PLEIADES) VS Dataset préannotés\n",
    "\n",
    "    src = config[\"donnees\"][\"source train\"]\n",
    "\n",
    "    if src == \"S2Looking\":\n",
    "        train_dataloader, valid_dataloader, test_dataloader = instantiate_dataloader_s2(config, list_output_dir)\n",
    "    else:\n",
    "        train_dataloader, valid_dataloader, test_dataloader = instantiate_dataloader_else(config, list_output_dir, output_test)\n",
    "\n",
    "    return train_dataloader, valid_dataloader, test_dataloader\n",
    "\n",
    "def instantiate_model(config):\n",
    "    \"\"\"\n",
    "    Instantiate a module based on the provided module type.\n",
    "\n",
    "    Args:\n",
    "        module_type (str): Type of module to instantiate.\n",
    "\n",
    "    Returns:\n",
    "        object: Instance of the specified module.\n",
    "    \"\"\"\n",
    "    print(\"Entre dans la fonction instantiate_model\")\n",
    "    module_type = config[\"optim\"][\"module\"]\n",
    "    nchannel = config[\"donnees\"][\"n channels train\"]\n",
    "\n",
    "    if module_type not in module_dict:\n",
    "        raise ValueError(\"Invalid module type\")\n",
    "\n",
    "    if module_type in [\"deeplabv3\", \"resnet50\"]:\n",
    "        return module_dict[module_type](nchannel)\n",
    "    else:\n",
    "        return module_dict[module_type]()\n",
    "\n",
    "\n",
    "def instantiate_loss(config):\n",
    "    \"\"\"\n",
    "    intantiates an optimizer object with the parameters\n",
    "    specified in the configuration file.\n",
    "\n",
    "    Args:\n",
    "        model: A PyTorch model object.\n",
    "        config: A dictionary object containing the configuration parameters.\n",
    "\n",
    "    Returns:\n",
    "        An optimizer object from the `torch.optim` module.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Entre dans la fonction instantiate_loss\")\n",
    "    loss_type = config[\"optim\"][\"loss\"]\n",
    "\n",
    "    if loss_type not in loss_dict:\n",
    "        raise ValueError(\"Invalid loss type\")\n",
    "    else:\n",
    "        return loss_dict[loss_type]()\n",
    "\n",
    "\n",
    "def instantiate_lightning_module(config):\n",
    "    \"\"\"\n",
    "    Create a PyTorch Lightning module for segmentation\n",
    "    with the given model and optimization configuration.\n",
    "\n",
    "    Args:\n",
    "        config (dict): Dictionary containing the configuration\n",
    "        parameters for optimization.\n",
    "        model: The PyTorch model to use for segmentation.\n",
    "\n",
    "    Returns:\n",
    "        A PyTorch Lightning module for segmentation.\n",
    "    \"\"\"\n",
    "    print(\"Entre dans la fonction instantiate_lighting_module\")\n",
    "    list_params = generate_optimization_elements(config)\n",
    "    task_type = config[\"donnees\"][\"task\"]\n",
    "\n",
    "    if task_type not in task_to_lightningmodule:\n",
    "        raise ValueError(\"Invalid task type\")\n",
    "    else:\n",
    "        LightningModule = task_to_lightningmodule[task_type]\n",
    "\n",
    "    lightning_module = LightningModule(\n",
    "        model=instantiate_model(config),\n",
    "        loss=instantiate_loss(config),\n",
    "        optimizer=list_params[0],\n",
    "        optimizer_params=list_params[1],\n",
    "        scheduler=list_params[2],\n",
    "        scheduler_params=list_params[3],\n",
    "        scheduler_interval=list_params[4],\n",
    "    )\n",
    "\n",
    "    return lightning_module\n",
    "\n",
    "def instantiate_trainer(config, lightning_module):\n",
    "    \"\"\"\n",
    "    Create a PyTorch Lightning module for segmentation with\n",
    "    the given model and optimization configuration.\n",
    "\n",
    "    Args:\n",
    "        config (dict): Dictionary containing the configuration\n",
    "        parameters for optimization.\n",
    "        model: The PyTorch model to use for segmentation.\n",
    "\n",
    "    Returns:\n",
    "        trainer: return a trainer object\n",
    "    \"\"\"\n",
    "    # def callbacks\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor=\"validation_loss\", save_top_k=1, save_last=True, mode=\"min\"\n",
    "    )\n",
    "\n",
    "    early_stop_callback = EarlyStopping(\n",
    "        monitor=\"validation_loss\", mode=\"min\", patience=5\n",
    "    )\n",
    "    lr_monitor = LearningRateMonitor(logging_interval=\"step\")\n",
    "\n",
    "    if config[\"donnees\"][\"task\"] == \"segmentation\":\n",
    "        checkpoint_callback_IOU = ModelCheckpoint(\n",
    "            monitor=\"validation_IOU\", save_top_k=1, save_last=True, mode=\"max\"\n",
    "        )\n",
    "        list_callbacks = [\n",
    "            lr_monitor,\n",
    "            checkpoint_callback,\n",
    "            early_stop_callback,\n",
    "            checkpoint_callback_IOU,\n",
    "        ]\n",
    "\n",
    "    if config[\"donnees\"][\"task\"] == \"classification\":\n",
    "        list_callbacks = [lr_monitor, checkpoint_callback, early_stop_callback]\n",
    "\n",
    "    if config[\"donnees\"][\"task\"] == \"change-detection\":\n",
    "        checkpoint_callback_IOU = ModelCheckpoint(\n",
    "                monitor=\"validation_IOU\", save_top_k=1, save_last=True, mode=\"max\"\n",
    "                )\n",
    "        list_callbacks = [lr_monitor, checkpoint_callback, early_stop_callback, checkpoint_callback_IOU]\n",
    "\n",
    "    strategy = \"auto\"\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        callbacks=list_callbacks,\n",
    "        max_epochs=config[\"optim\"][\"max epochs\"],\n",
    "        num_sanity_val_steps=2,\n",
    "        strategy=strategy,\n",
    "        log_every_n_steps=2,\n",
    "        accumulate_grad_batches=config[\"optim\"][\"accumulate batch\"],\n",
    "    )\n",
    "\n",
    "    return trainer\n",
    "\n",
    "\n",
    "def run_pipeline(remote_server_uri, experiment_name, run_name):\n",
    "    \"\"\"\n",
    "    Runs the segmentation pipeline u\n",
    "    sing the configuration specified in `config.yml`\n",
    "    and the provided MLFlow parameters.\n",
    "    Args:\n",
    "        None\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Open the file and load the file\n",
    "    with open(\"../config.yml\") as f:\n",
    "        config = yaml.load(f, Loader=SafeLoader)\n",
    "\n",
    "    tile_size = config[\"donnees\"][\"tile size\"]\n",
    "    batch_size_test = config[\"optim\"][\"batch size test\"]\n",
    "    task_type = config[\"donnees\"][\"task\"]\n",
    "    source_data = config[\"donnees\"][\"source train\"]\n",
    "    src_task = source_data + task_type\n",
    "\n",
    "    list_data_dir, list_masks_cloud_dir, test_dir = download_data(config)\n",
    "\n",
    "    list_output_dir = prepare_train_data(config, list_data_dir, list_masks_cloud_dir)\n",
    "    output_test = prepare_test_data(config, test_dir)\n",
    "\n",
    "    train_dl, valid_dl, test_dl = instantiate_dataloader(config, list_output_dir, output_test)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    # train_dl.dataset[0][0].shape\n",
    "    light_module = instantiate_lightning_module(config)\n",
    "    trainer = instantiate_trainer(config, light_module)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    remote_server_uri = \"https://projet-slums-detection-128833.user.lab.sspcloud.fr\"\n",
    "    # experiment_name = \"classification\"\n",
    "    # run_name = \"mergemain\"\n",
    "\n",
    "    # model = mlflow.pytorch.load_model('/home/onyxia/work/detection-habitat-spontane/src/old_model/model/')\n",
    "\n",
    "    if config[\"mlflow\"]:\n",
    "        update_storage_access()\n",
    "        os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"https://minio.lab.sspcloud.fr\"\n",
    "        mlflow.end_run()\n",
    "        mlflow.set_tracking_uri(remote_server_uri)\n",
    "        mlflow.set_experiment(experiment_name)\n",
    "        # mlflow.pytorch.autolog()\n",
    "\n",
    "        with mlflow.start_run(run_name=run_name):\n",
    "            mlflow.autolog()\n",
    "            mlflow.log_artifact(\n",
    "                \"../config.yml\",\n",
    "                artifact_path=\"config.yml\"\n",
    "            )\n",
    "            trainer.fit(light_module, train_dl, valid_dl)\n",
    "\n",
    "            light_module = light_module.load_from_checkpoint(\n",
    "                loss=instantiate_loss(config),\n",
    "                #checkpoint_path=trainer.checkpoint_callback.best_model_path, #je créé un module qui charge\n",
    "                checkpoint_path='epoch=14-step=13545.ckpt',\n",
    "                model=light_module.model,\n",
    "                # model=model,\n",
    "                optimizer=light_module.optimizer,\n",
    "                optimizer_params=light_module.optimizer_params,\n",
    "                scheduler=light_module.scheduler,\n",
    "                scheduler_params=light_module.scheduler_params,\n",
    "                scheduler_interval=light_module.scheduler_interval\n",
    "            )\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "            model = light_module.model\n",
    "\n",
    "            if src_task not in task_to_evaluation:\n",
    "                raise ValueError(\"Invalid task type\")\n",
    "            else:\n",
    "                evaluer_modele_sur_jeu_de_test = task_to_evaluation[src_task]\n",
    "            \n",
    "            # from classes.optim.evaluation_model import proba_classification_pleiade\n",
    "            # proba_classification_pleiade(\n",
    "            #         test_dl,\n",
    "            #         model,\n",
    "            #         tile_size,\n",
    "            #         batch_size_test,\n",
    "            #         config[\"donnees\"][\"n bands\"],\n",
    "            #         False\n",
    "            #     )\n",
    "\n",
    "            evaluer_modele_sur_jeu_de_test(\n",
    "                    test_dl,\n",
    "                    model,\n",
    "                    tile_size,\n",
    "                    batch_size_test,\n",
    "                    config[\"donnees\"][\"n bands\"],\n",
    "                    False\n",
    "                    #config[\"mlflow\"]\n",
    "                )\n",
    "\n",
    "            # if task_type == \"classification\":\n",
    "            #     model_uri = mlflow.get_artifact_uri(\"model\")\n",
    "            #     print(model_uri)\n",
    "\n",
    "            #     mlflow.evaluate(\n",
    "            #         model_uri,\n",
    "            #         test_dl,\n",
    "            #         targets=\"labels\",\n",
    "            #         model_type=\"classifier\",\n",
    "            #         evaluators=[\"default\"]\n",
    "            #     )\n",
    "\n",
    "    else:\n",
    "        trainer.fit(light_module, train_dl, valid_dl)\n",
    "\n",
    "        light_module = light_module.load_from_checkpoint(\n",
    "            loss=instantiate_loss(config),\n",
    "            checkpoint_path=trainer.checkpoint_callback.best_model_path,  # je créé un module qui charge\n",
    "            # checkpoint_path='epoch=15-step=16048.ckpt',\n",
    "            model=light_module.model,\n",
    "            optimizer=light_module.optimizer,\n",
    "            optimizer_params=light_module.optimizer_params,\n",
    "            scheduler=light_module.scheduler,\n",
    "            scheduler_params=light_module.scheduler_params,\n",
    "            scheduler_interval=light_module.scheduler_interval\n",
    "        )\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "        model = light_module.model\n",
    "\n",
    "        from classes.optim.evaluation_model import predicted_labels_classification_pleiade, variation_threshold_classification_pleiades\n",
    "        variation_threshold_classification_pleiades(\n",
    "            test_dl, model, tile_size, batch_size_test, n_bands=3, use_mlflow=False\n",
    "        )\n",
    "        predicted_labels_classification_pleiade(\n",
    "            test_dl,\n",
    "            model,\n",
    "            tile_size,\n",
    "            batch_size_test,\n",
    "            config[\"donnees\"][\"n bands\"],\n",
    "            False,\n",
    "        )\n",
    "\n",
    "        # from classes.optim.evaluation_model import metrics_classification_pleiade2, evaluer_modele_sur_jeu_de_test_classification_pleiade2\n",
    "        # trshld = metrics_classification_pleiade2(\n",
    "        #     test_dl,\n",
    "        #     model,\n",
    "        #     tile_size,\n",
    "        #     batch_size_test,\n",
    "        #     config[\"donnees\"][\"n bands\"],\n",
    "        #     False,\n",
    "        # )\n",
    "        # print(trshld)\n",
    "        # evaluer_modele_sur_jeu_de_test_classification_pleiade2(\n",
    "        #     test_dl,\n",
    "        #     model,\n",
    "        #     tile_size,\n",
    "        #     batch_size_test,\n",
    "        #     config[\"donnees\"][\"n bands\"],\n",
    "        #     False,\n",
    "        # )\n",
    "\n",
    "        if src_task not in task_to_evaluation:\n",
    "            raise ValueError(\"Invalid task type\")\n",
    "        else:\n",
    "            evaluer_modele_sur_jeu_de_test = task_to_evaluation[src_task]\n",
    "\n",
    "        evaluer_modele_sur_jeu_de_test(\n",
    "            test_dl,\n",
    "            model,\n",
    "            tile_size,\n",
    "            batch_size_test,\n",
    "            config[\"donnees\"][\"n bands\"],\n",
    "            config[\"mlflow\"],\n",
    "        )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # MLFlow params\n",
    "    remote_server_uri = sys.argv[1]\n",
    "    experiment_name = sys.argv[2]\n",
    "    run_name = sys.argv[3]\n",
    "    run_pipeline(remote_server_uri, experiment_name, run_name)\n",
    "\n",
    "\n",
    "# nohup python run_training_pipeline.py\n",
    "# https://projet-slums-detection-128833.user.lab.sspcloud.fr\n",
    "# classification 2022_2018_971 > out.txt &\n",
    "# https://www.howtogeek.com/804823/nohup-command-linux/\n",
    "# TO DO :\n",
    "# test routine sur S2Looking dataset\n",
    "# import os\n",
    "\n",
    "# list_data_dir = [\"../data/PLEIADES/2022/MARTINIQUE/\"]\n",
    "# def delete_files_in_dir(dir_path,length_delete):\n",
    "#    # Get a list of all the files in the directory\n",
    "#  files = os.listdir(dir_path)[:length_delete]\n",
    "\n",
    "#  for file in files:\n",
    "#        file_path = os.path.join(dir_path, file)\n",
    "#        if os.path.isfile(file_path):\n",
    "#            os.remove(file_path)\n",
    "# delete_files_in_dir(list_data_dir[0], 600)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
