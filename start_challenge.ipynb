{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e0018fb-f29e-4c6a-a713-c9f82ff0a440",
   "metadata": {},
   "source": [
    "# Libraries and s3 connexion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67017e6c-b574-4428-bbc9-fde13c8e606d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting h5py\n",
      "  Downloading h5py-3.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.12/site-packages (from h5py) (2.1.0)\n",
      "Downloading h5py-3.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: h5py\n",
      "Successfully installed h5py-3.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "41440b7f-1caa-40f2-b113-43e7e671de7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import s3fs\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ec08b6d9-d78d-4042-9073-aa973148633f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = s3fs.S3FileSystem(\n",
    "    client_kwargs={\"endpoint_url\": f'https://{os.environ[\"AWS_S3_ENDPOINT\"]}'},\n",
    "    key=os.environ[\"AWS_ACCESS_KEY_ID\"],\n",
    "    secret=os.environ[\"AWS_SECRET_ACCESS_KEY\"],\n",
    "    token=os.environ[\"AWS_SESSION_TOKEN\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4dd2d8-2e6b-4db0-b396-f8b870a0e68a",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fee0f6df-d5c0-43de-b0cc-1855bd7be8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargement de projet-slums-detection/challenge_mexique/.keep vers satellite-images-challenge-human-settlements/data/.keep\n",
      "Téléchargement de projet-slums-detection/challenge_mexique/SampleSubmission.csv vers satellite-images-challenge-human-settlements/data/SampleSubmission.csv\n",
      "Téléchargement de projet-slums-detection/challenge_mexique/id_map.csv vers satellite-images-challenge-human-settlements/data/id_map.csv\n",
      "Téléchargement de projet-slums-detection/challenge_mexique/test_data.h5 vers satellite-images-challenge-human-settlements/data/test_data.h5\n",
      "Téléchargement de projet-slums-detection/challenge_mexique/train_data.h5 vers satellite-images-challenge-human-settlements/data/train_data.h5\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m s3_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchallenge_mexique/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     29\u001b[0m local_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msatellite-images-challenge-human-settlements/data/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 31\u001b[0m \u001b[43mdownload_s3_folder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbucket_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms3_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[96], line 24\u001b[0m, in \u001b[0;36mdownload_s3_folder\u001b[0;34m(fs, bucket_name, s3_folder, local_dir)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Télécharger le fichier\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTéléchargement de \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m vers \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlocal_file_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_file_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/fsspec/asyn.py:118\u001b[0m, in \u001b[0;36msync_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m obj \u001b[38;5;129;01mor\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/fsspec/asyn.py:103\u001b[0m, in \u001b[0;36msync\u001b[0;34m(loop, func, timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FSTimeoutError \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreturn_result\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(return_result, \u001b[38;5;167;01mBaseException\u001b[39;00m):\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m return_result\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m return_result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/fsspec/asyn.py:56\u001b[0m, in \u001b[0;36m_runner\u001b[0;34m(event, coro, result, timeout)\u001b[0m\n\u001b[1;32m     54\u001b[0m     coro \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mwait_for(coro, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 56\u001b[0m     result[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m coro\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m     58\u001b[0m     result[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m ex\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/fsspec/asyn.py:665\u001b[0m, in \u001b[0;36mAsyncFileSystem._get\u001b[0;34m(self, rpath, lpath, recursive, callback, maxdepth, **kwargs)\u001b[0m\n\u001b[1;32m    663\u001b[0m     get_file \u001b[38;5;241m=\u001b[39m callback\u001b[38;5;241m.\u001b[39mbranch_coro(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_file)\n\u001b[1;32m    664\u001b[0m     coros\u001b[38;5;241m.\u001b[39mappend(get_file(rpath, lpath, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[0;32m--> 665\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m _run_coros_in_chunks(\n\u001b[1;32m    666\u001b[0m     coros, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, callback\u001b[38;5;241m=\u001b[39mcallback\n\u001b[1;32m    667\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/fsspec/asyn.py:268\u001b[0m, in \u001b[0;36m_run_coros_in_chunks\u001b[0;34m(coros, batch_size, callback, timeout, return_exceptions, nofiles)\u001b[0m\n\u001b[1;32m    266\u001b[0m     done, pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mwait(pending, return_when\u001b[38;5;241m=\u001b[39masyncio\u001b[38;5;241m.\u001b[39mFIRST_COMPLETED)\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m done:\n\u001b[0;32m--> 268\u001b[0m         result, k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m done\u001b[38;5;241m.\u001b[39mpop()\n\u001b[1;32m    269\u001b[0m         results[k] \u001b[38;5;241m=\u001b[39m result\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/fsspec/asyn.py:245\u001b[0m, in \u001b[0;36m_run_coros_in_chunks.<locals>._run_coro\u001b[0;34m(coro, i)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_coro\u001b[39m(coro, i):\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 245\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mwait_for(coro, timeout\u001b[38;5;241m=\u001b[39mtimeout), i\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    247\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_exceptions:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/asyncio/tasks.py:520\u001b[0m, in \u001b[0;36mwait_for\u001b[0;34m(fut, timeout)\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m timeouts\u001b[38;5;241m.\u001b[39mtimeout(timeout):\n\u001b[0;32m--> 520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fut\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/fsspec/callbacks.py:81\u001b[0m, in \u001b[0;36mCallback.branch_coro.<locals>.func\u001b[0;34m(path1, path2, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc\u001b[39m(path1, path2: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbranched(path1, path2, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m child:\n\u001b[0;32m---> 81\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fn(path1, path2, callback\u001b[38;5;241m=\u001b[39mchild, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/s3fs/core.py:1332\u001b[0m, in \u001b[0;36mS3FileSystem._get_file\u001b[0;34m(self, rpath, lpath, callback, version_id, **kwargs)\u001b[0m\n\u001b[1;32m   1330\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1331\u001b[0m             bytes_read \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[0;32m-> 1332\u001b[0m             segment_len \u001b[38;5;241m=\u001b[39m \u001b[43mf0\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1333\u001b[0m             callback\u001b[38;5;241m.\u001b[39mrelative_update(segment_len)\n\u001b[1;32m   1334\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "# Initialiser le système de fichiers S3\n",
    "def download_s3_folder(fs, bucket_name, s3_folder, local_dir):\n",
    "    \"\"\"\n",
    "    Télécharge tous les fichiers d'un dossier S3 dans un répertoire local.\n",
    "    \n",
    "    :param bucket_name: Nom du bucket S3.\n",
    "    :param s3_folder: Chemin du dossier sur S3 à télécharger.\n",
    "    :param local_dir: Chemin local où télécharger les fichiers.\n",
    "    \"\"\"\n",
    "    # Liste des fichiers dans le dossier S3\n",
    "    files = fs.ls(f\"{bucket_name}/{s3_folder}\")\n",
    "\n",
    "    for file in files:\n",
    "        file_path = file.replace(bucket_name+s3_folder, \"\")\n",
    "        local_file_path = os.path.join(local_dir, file_path)\n",
    "\n",
    "        # Créer les répertoires locaux si nécessaire\n",
    "        local_file_dir = os.path.dirname(local_file_path)\n",
    "        if not os.path.exists(local_file_dir):\n",
    "            os.makedirs(local_file_dir)\n",
    "\n",
    "        # Télécharger le fichier\n",
    "        print(f\"Téléchargement de {file} vers {local_file_path}\")\n",
    "        fs.get(file, local_file_path)\n",
    "\n",
    "# Exemples d'utilisation\n",
    "bucket_name = 'projet-slums-detection/'\n",
    "s3_folder = 'challenge_mexique/'\n",
    "local_dir = 'satellite-images-challenge-human-settlements/data/'\n",
    "\n",
    "download_s3_folder(fs, bucket_name, s3_folder, local_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309e1a72-b333-4d65-ad16-364d7943fb32",
   "metadata": {},
   "source": [
    "## Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24c54df6-8a25-4920-9cce-0a85394c65d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_889/308163644.py:7: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n",
      "  X = np.array(hdf['images'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X (images): (1100000, 16, 16, 6)\n",
      "Shape of y (labels): (1100000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_889/308163644.py:10: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n",
      "  y = np.array(hdf['labels'])\n"
     ]
    }
   ],
   "source": [
    "# Path to your HDF5 file\n",
    "hdf5_file = \"data/train_data.h5\"\n",
    "\n",
    "# Open the HDF5 file\n",
    "with h5py.File(hdf5_file, 'r') as hdf:\n",
    "    # Extract the images (X)\n",
    "    X = np.array(hdf['images'])\n",
    "    \n",
    "    # Extract the labels (y)\n",
    "    y = np.array(hdf['labels'])\n",
    "\n",
    "# Check the shapes to ensure they are correct\n",
    "print(\"Shape of X (images):\", X.shape)\n",
    "print(\"Shape of y (labels):\", y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776ce6fa-05c0-4374-9460-63044111f44b",
   "metadata": {},
   "source": [
    "### Visualize first image (uint16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "90198231-a07c-4510-8df7-7137f05eeda6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot l'image 50\n",
    "image_array = X[50]\n",
    "\n",
    "rgb_image = np.stack([image_array[:, :, 0], image_array[:, :, 1], image_array[:, :, 2]], axis=-1)\n",
    "\n",
    "# Normalize the image for display (optional if values exceed standard 8-bit range)\n",
    "rgb_image_normalized = rgb_image / np.max(rgb_image)\n",
    "\n",
    "# Plot the RGB image\n",
    "plt.imshow(rgb_image_normalized)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daddeb19-f826-4a14-9b77-21df84373eca",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "73622f54-fa40-436c-946f-342ebeb29789",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_889/3349114931.py:5: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n",
      "  X_test = np.array(hdf['images'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_test (images): (120000, 16, 16, 6)\n"
     ]
    }
   ],
   "source": [
    "hdf5_file_test = \"data/test_data.h5\"\n",
    "# Open the HDF5 file\n",
    "with h5py.File(hdf5_file_test, 'r') as hdf:\n",
    "    # Extract the images (X)\n",
    "    X_test = np.array(hdf['images'])\n",
    "\n",
    "# Check the shapes to ensure they are correct\n",
    "print(\"Shape of X_test (images):\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2ca083-2281-4927-9d7a-12dd48431c26",
   "metadata": {},
   "source": [
    "### Create y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "19ceac53-7bfc-425d-b4a9-55bf6e804f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = pd.read_csv(\"data/id_map.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b3cb409a-dc9f-4cc1-a550-5f54585d221c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv(\"data/SampleSubmission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "61b0b8f0-e07c-43a6-9558-bdf43b065410",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.merge(sample, mapping, on=\"id\")\n",
    "y_test = y_test.sort_values(by=\"ID\", ascending=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "y_test = np.array(y_test['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ee615f-a496-4c17-b188-5f1d38ee96a8",
   "metadata": {},
   "source": [
    "### Balance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cf89543b-2b49-4fc1-812b-18166da0553a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_data(X, y, prop_of_zeros=0.2):\n",
    "    # Step 1: Count the number of 1's in y\n",
    "    num_ones = np.sum(y == 1)\n",
    "    \n",
    "    # Step 2: Get indices of 0's and 1's in y\n",
    "    ones_indices = np.where(y == 1)[0]\n",
    "    zeros_indices = np.where(y == 0)[0]\n",
    "    \n",
    "    # Step 3: Randomly sample the same number of 0's as there are 1's\n",
    "    balanced_zero_indices = np.random.choice(zeros_indices, int(int(num_ones)*prop_of_zeros), replace=False)\n",
    "    \n",
    "    # Step 4: Combine indices of 0's and 1's\n",
    "    balanced_indices = np.concatenate([ones_indices, balanced_zero_indices])\n",
    "    \n",
    "    # Step 5: Create balanced X and y\n",
    "    X_balanced = X[balanced_indices]\n",
    "    y_balanced = y[balanced_indices]\n",
    "    \n",
    "    # Display the number of 0's and 1's in the balanced y\n",
    "    print(f\"Number of 1's in balanced y: {np.sum(y_balanced == 1)}\")\n",
    "    print(f\"Number of 0's in balanced y: {np.sum(y_balanced == 0)}\")\n",
    "\n",
    "    # Shuffle both X_balanced and y_balanced together\n",
    "    X_train, y_train = shuffle(X_balanced, y_balanced, random_state=1)\n",
    "\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a18a55d6-48b5-41a1-bffb-39c89fe76af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 1's in balanced y: 100000\n",
      "Number of 0's in balanced y: 20000\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = balance_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c586387a-076e-43d5-98a4-20ccdee287a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120000, 16, 16, 6)\n",
      "(120000, 16, 16, 6)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffb6798-0d92-4654-ae49-796c426339bf",
   "metadata": {},
   "source": [
    "### Baseline models\n",
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b84b0f6-20b8-417c-8727-fb88d29870c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline RF model training accuracy: 0.9999\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Flatten the image data\n",
    "X_train_flat = X_train.reshape(X_train.shape[0], -1)  \n",
    "X_test_flat = X_test.reshape(X_test.shape[0], -1)  \n",
    "\n",
    "# Define and train the baseline model\n",
    "rf = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "rf.fit(X_train_flat, y_train)\n",
    "\n",
    "y_pred_train = rf.predict(X_train_flat)\n",
    "y_pred_test = rf.predict(X_test_flat)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "train_accuracy_rf = accuracy_score(y_train, y_pred_train)\n",
    "\n",
    "## 0.9999 accuracy: OVERFITTING\n",
    "print(f'Baseline RF model training accuracy: {train_accuracy_rf:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da25bcf-660e-4cc5-82b1-68be1f7ee44a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "669abbec-1080-48fa-bf2f-de9ae47d7ee6",
   "metadata": {},
   "source": [
    "#### Multi layer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d61eb7c7-936c-40dd-a928-c6a05604a7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MLP model training accuracy: 0.6053\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Flatten the image data\n",
    "X_train_flat = X_train.reshape(X_train.shape[0], -1)  \n",
    "X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "# Scale the data to [0,1]\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_flat)\n",
    "X_test_scaled = scaler.transform(X_test_flat)\n",
    "\n",
    "# Define and train the MLP model\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(50,), max_iter=20, random_state=42)\n",
    "mlp_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_train_mlp = mlp_model.predict(X_train_scaled)\n",
    "y_pred_test_mlp = mlp_model.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "train_accuracy_mlp = accuracy_score(y_train, y_pred_train_mlp)\n",
    "\n",
    "\n",
    "## ~0.60 accuracy: UNDERFITTING\n",
    "print(f'Baseline MLP model training accuracy: {train_accuracy_mlp:.4f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccfc4fc-c4fd-4410-b34e-b01c5c732482",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
