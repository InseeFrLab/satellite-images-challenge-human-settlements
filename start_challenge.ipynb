{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e0018fb-f29e-4c6a-a713-c9f82ff0a440",
   "metadata": {},
   "source": [
    "# Libraries and s3 connexion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67017e6c-b574-4428-bbc9-fde13c8e606d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install h5py rasterio torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41440b7f-1caa-40f2-b113-43e7e671de7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import s3fs\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec08b6d9-d78d-4042-9073-aa973148633f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = s3fs.S3FileSystem(\n",
    "    client_kwargs={\"endpoint_url\": f'https://{os.environ[\"AWS_S3_ENDPOINT\"]}'},\n",
    "    key=os.environ[\"AWS_ACCESS_KEY_ID\"],\n",
    "    secret=os.environ[\"AWS_SECRET_ACCESS_KEY\"],\n",
    "    token=os.environ[\"AWS_SESSION_TOKEN\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4dd2d8-2e6b-4db0-b396-f8b870a0e68a",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee0f6df-d5c0-43de-b0cc-1855bd7be8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_s3_folder(fs, bucket_name, s3_folder, local_dir):\n",
    "    \"\"\"\n",
    "    Télécharge tous les fichiers d'un dossier S3 dans un répertoire local.\n",
    "    \n",
    "    :param bucket_name: Nom du bucket S3.\n",
    "    :param s3_folder: Chemin du dossier sur S3 à télécharger.\n",
    "    :param local_dir: Chemin local où télécharger les fichiers.\n",
    "    \"\"\"\n",
    "    files = fs.ls(f\"{bucket_name}/{s3_folder}\")\n",
    "\n",
    "    for file in files:\n",
    "        file_path = file.replace(bucket_name+s3_folder, \"\")\n",
    "        local_file_path = os.path.join(local_dir, file_path)\n",
    "\n",
    "        local_file_dir = os.path.dirname(local_file_path)\n",
    "        if not os.path.exists(local_file_dir):\n",
    "            os.makedirs(local_file_dir)\n",
    "\n",
    "        print(f\"Téléchargement de {file} vers {local_file_path}\")\n",
    "        fs.get(file, local_file_path)\n",
    "\n",
    "# Téléchargement des données\n",
    "bucket_name = 'projet-slums-detection/'\n",
    "s3_folder = 'challenge_mexique/'\n",
    "local_dir = 'data/'\n",
    "\n",
    "download_s3_folder(fs, bucket_name, s3_folder, local_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309e1a72-b333-4d65-ad16-364d7943fb32",
   "metadata": {},
   "source": [
    "## Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c54df6-8a25-4920-9cce-0a85394c65d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your HDF5 file\n",
    "hdf5_file = \"data/train_data.h5\"\n",
    "\n",
    "# Open the HDF5 file\n",
    "with h5py.File(hdf5_file, 'r') as hdf:\n",
    "    # Extract the images (X)\n",
    "    X = np.array(hdf['images'])\n",
    "    \n",
    "    # Extract the labels (y)\n",
    "    y = np.array(hdf['labels'])\n",
    "\n",
    "# Check the shapes to ensure they are correct\n",
    "print(\"Shape of X (images):\", X.shape)\n",
    "print(\"Shape of y (labels):\", y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776ce6fa-05c0-4374-9460-63044111f44b",
   "metadata": {},
   "source": [
    "### Visualize first image (uint16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90198231-a07c-4510-8df7-7137f05eeda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot l'image 50\n",
    "image_array = X[50]\n",
    "\n",
    "rgb_image = np.stack([image_array[:, :, 3], image_array[:, :, 4], image_array[:, :, 5]], axis=-1)\n",
    "\n",
    "# Normalize the image for display (optional if values exceed standard 8-bit range)\n",
    "rgb_image_normalized = rgb_image / np.max(rgb_image)\n",
    "\n",
    "# Plot the RGB image\n",
    "plt.imshow(rgb_image_normalized)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daddeb19-f826-4a14-9b77-21df84373eca",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73622f54-fa40-436c-946f-342ebeb29789",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_file_test = \"data/test_data.h5\"\n",
    "# Open the HDF5 file\n",
    "with h5py.File(hdf5_file_test, 'r') as hdf:\n",
    "    # Extract the images (X)\n",
    "    X_test = np.array(hdf['images'])\n",
    "\n",
    "# Check the shapes to ensure they are correct\n",
    "print(\"Shape of X_test (images):\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2ca083-2281-4927-9d7a-12dd48431c26",
   "metadata": {},
   "source": [
    "### Create y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ceac53-7bfc-425d-b4a9-55bf6e804f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = pd.read_csv(\"data/id_map.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cb409a-dc9f-4cc1-a550-5f54585d221c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv(\"data/SampleSubmission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b0b8f0-e07c-43a6-9558-bdf43b065410",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.merge(sample, mapping, on=\"id\")\n",
    "y_test = y_test.sort_values(by=\"ID\", ascending=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "y_test = np.array(y_test['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ee615f-a496-4c17-b188-5f1d38ee96a8",
   "metadata": {},
   "source": [
    "### Balance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf89543b-2b49-4fc1-812b-18166da0553a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_data(X, y, prop_of_zeros=0.5):\n",
    "    # Step 1: Count the number of 1's in y\n",
    "    num_ones = np.sum(y == 1)\n",
    "    \n",
    "    # Step 2: Get indices of 0's and 1's in y\n",
    "    ones_indices = np.where(y == 1)[0]\n",
    "    zeros_indices = np.where(y == 0)[0]\n",
    "    \n",
    "    # Step 3: Randomly sample the same number of 0's as there are 1's\n",
    "    balanced_zero_indices = np.random.choice(zeros_indices, int(int(num_ones)*prop_of_zeros), replace=False)\n",
    "    \n",
    "    # Step 4: Combine indices of 0's and 1's\n",
    "    balanced_indices = np.concatenate([ones_indices, balanced_zero_indices])\n",
    "    \n",
    "    # Step 5: Create balanced X and y\n",
    "    X_balanced = X[balanced_indices]\n",
    "    y_balanced = y[balanced_indices]\n",
    "    \n",
    "    # Display the number of 0's and 1's in the balanced y\n",
    "    print(f\"Number of 1's in balanced y: {np.sum(y_balanced == 1)}\")\n",
    "    print(f\"Number of 0's in balanced y: {np.sum(y_balanced == 0)}\")\n",
    "\n",
    "    # Shuffle both X_balanced and y_balanced together\n",
    "    X_train, y_train = shuffle(X_balanced, y_balanced, random_state=1)\n",
    "\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18a55d6-48b5-41a1-bffb-39c89fe76af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = balance_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c586387a-076e-43d5-98a4-20ccdee287a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3979063c-4f54-4274-871b-0775c04b5f0c",
   "metadata": {},
   "source": [
    "## Entrainements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1fac74-987c-4fbc-a9e4-a63e95668008",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.multiprocessing as multiprocessing\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torchvision.models.resnet import ResNet50_Weights\n",
    "\n",
    "# Increase the shared memory limit\n",
    "multiprocessing.set_sharing_strategy(\"file_system\")\n",
    "\n",
    "\n",
    "class ResNet50Module(nn.Module):\n",
    "    \"\"\"\n",
    "    Finetuned ResNet50 model for binary classification.\n",
    "\n",
    "    The model is based on the ResNet50 architecture and has been trained on a\n",
    "    specific task to classify inputs into two labels.\n",
    "\n",
    "    Args:\n",
    "        n_channel: (int) number of channels of the input image\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The output tensor containing the probabilities\n",
    "        for each class.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, nchannel=6):\n",
    "        super().__init__()\n",
    "        # Load the pre-trained ResNet50 model\n",
    "        self.model = torchvision.models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "\n",
    "        # Replace the last fully connected layer\n",
    "        self.model.fc = nn.Linear(2048, 2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        if nchannel != 3:\n",
    "            self.model.conv1 = nn.Conv2d(\n",
    "                nchannel,\n",
    "                64,\n",
    "                kernel_size=(7, 7),\n",
    "                stride=(2, 2),\n",
    "                padding=(3, 3),\n",
    "                bias=False,\n",
    "            )\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Performs the forward pass of the model.\n",
    "\n",
    "        Args:\n",
    "            input (torch.Tensor): The input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The output probabilities after applying the\n",
    "            softmax activation.\n",
    "        \"\"\"\n",
    "        output = self.model(input)\n",
    "        probabilities = torch.softmax(output, dim=1)\n",
    "\n",
    "        return probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffb6798-0d92-4654-ae49-796c426339bf",
   "metadata": {},
   "source": [
    "### Baseline models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
